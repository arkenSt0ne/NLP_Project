{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fin_LSTM_TE.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5vZkZw1wEPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tensorflow==2.0.0-alpha0\n",
        "# %reload_ext tensorboard.notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo5Vc9Q5wp_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# import torchnlp.nn as nlp_nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import json\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "torch.manual_seed(1)\n",
        "# from tensorflow import summary\n",
        "import random\n",
        "from torch.autograd import Variable\n",
        "# import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi7bwQ3RIVTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY7c-aRu0SUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torchviz\n",
        "from torchviz import make_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkTTAh2NmTcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a = []\n",
        "# while(1):\n",
        "#     a.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d14u5VwrwLeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# current_time = str(datetime.datetime.now().timestamp())\n",
        "# train_log_dir = 'logs/tensorboard/train/' + current_time\n",
        "# test_log_dir = 'logs/tensorboard/test/' + current_time\n",
        "# train_summary_writer = summary.create_file_writer(train_log_dir)\n",
        "# test_summary_writer = summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uis-Ug4peLeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4C6lz2swobw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_TE(nn.Module):\n",
        "    def __init__(self, embedding_dim,hidden_dim, vocab_size, class_numbers):\n",
        "        super(LSTM_TE, self).__init__()\n",
        "        self.H = hidden_dim\n",
        "        self.K = class_numbers\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, self.H)\n",
        "        self.att = nn.Linear(self.H, self.K,bias = True)\n",
        "        self.att_norm = nn.Softmax(dim = 0)\n",
        "        self.act = nn.Sigmoid()\n",
        "        self.fin_ = nn.Softmax(dim = 0)\n",
        "        self.fcs = [ nn.Linear(self.H,1) for _ in range(self.K)]\n",
        "        self.c_prob = [ nn.Sigmoid() for _ in range(self.K)]\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        lstm_out = lstm_out.view(len(sentence),self.H)\n",
        "        att_denorm = self.att(lstm_out.view(len(sentence), -1)) # a_t = W_att * h_t + b_att\n",
        "        att_denorm = self.act(att_denorm)       # a_t = sigmoid(a_t)\n",
        "        As = self.att_norm(att_denorm) # A = softmax_row({a_1,..,a_d}^T)\n",
        "        As = As.view(len(sentence),self.K) # A = D*K\n",
        "        T = torch.zeros((self.H,self.K))\n",
        "        for i in range(self.H):\n",
        "          T[i] = torch.mul(torch.transpose(As,0,1),torch.transpose(lstm_out,0,1)[i]).sum(dim=1)\n",
        "        # tag_scores  = torch.mul(As,lstm_out) # produce T = {T1,..,TK} \n",
        "        # tag_scores = self.fin_(tag_scores.sum(dim = 0)) \n",
        "        T = torch.transpose(T,0,1)\n",
        "\n",
        "        rt = torch.zeros((self.K,1)).to(device)\n",
        "        for i in range(self.K):\n",
        "          rt[i] = self.fcs[i](T[i])\n",
        "          rt[i] = self.c_prob[i](rt[i])\n",
        "        return  rt\n",
        "    def init_hidden(self,batch_size):\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        weights = next(self.parameters()).data\n",
        "        h = (weights.new(1, batch_size, self.hidden_dim).zero_().to(device),\n",
        "             weights.new(1, batch_size, self.hidden_dim).zero_().to(device))\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdOMQ5j-S8oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = LSTM_TE(5, 3, 4000, 8).to(device) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK35FuXCWENg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inp = [ random.randint(1,30) for _ in range(5)]\n",
        "# inp = torch.tensor(inp,dtype = torch.long).to(device)\n",
        "# L  = model(inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3wzbEF-X8x7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(L)\n",
        "# # print(a.shape,b.shape)\n",
        "# # torch.mul(torch.transpose(a,0,1),torch.transpose(b,0,1)[0]).sum(dim = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LIawZHzcXfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make_dot(L)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unbiRI7uxD36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parse the data\n",
        "# load drive\n",
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my3YQpeOxQKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load vocab\n",
        "root_path = '/content/gdrive/My Drive/RDoCTask2019TrainTestData/RDoCTask1TrainData'\n",
        "with open(root_path+\"/vocab\",\"r\") as f:\n",
        "  vocab = json.load(f)\n",
        "  f.close()\n",
        "df =pd.read_csv(root_path+\"/train_csv\")\n",
        "root_path2 = '/content/gdrive/My Drive/RDoCTask2019TrainTestData/RDoCTask1TestData'\n",
        "df2 =pd.read_csv(root_path+\"/test_csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G9E_DnDxagm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_to_idx(w):\n",
        "  return vocab(w)\n",
        "def sent_to_idxs(txt):\n",
        "  lx = len(vocab.keys())\n",
        "  return [ vocab[w] if w in vocab.keys() else lx for w in txt]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di-kWQrhxeFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def listStr_lst(x):\n",
        "  if type(x) != list:\n",
        "    x = x[1:-1].split(\",\")\n",
        "    x = list(map(lambda y: y.strip()[1:-1],x))\n",
        "  return x\n",
        "df.title = df.title.apply(lambda x: listStr_lst(x))\n",
        "df.abstract = df.abstract.apply(lambda x: listStr_lst(x))\n",
        "df['inp'] = df.title + df.abstract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZLPBhbXxkMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['inp'] = df['inp'].apply( lambda x : sent_to_idxs(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZocJmMhq6nk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.title = df2.title.apply(lambda x: listStr_lst(x))\n",
        "df2.abstract = df2.abstract.apply(lambda x: listStr_lst(x))\n",
        "df2['inp'] = df2.title + df2.abstract\n",
        "df2['inp'] = df2['inp'].apply( lambda x : sent_to_idxs(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFjWjOwmw-T6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hWlOYjT7KiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.columns =['pmid', 'title', 'abstract', 'y_belong',\n",
        "       'Relevant Context', 'label', 'inp']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogfr5WPvxm7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(vocab.keys()) + 2 # indexing from 1 and 1 extra for unknown words\n",
        "CLASS_SIZE = 8\n",
        "EMBED_DIM = 128\n",
        "HIDDEN_DIM = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99psGgSQg3j7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class LSTMTagger(nn.Module):\n",
        "\n",
        "#     def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "#         super(LSTMTagger, self).__init__()\n",
        "#         self.hidden_dim = hidden_dim\n",
        "\n",
        "#         self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "#         # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "#         # with dimensionality hidden_dim.\n",
        "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "#         # The linear layer that maps from hidden state space to tag space\n",
        "#         self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "#     def forward(self, sentence):\n",
        "#         embeds = self.word_embeddings(sentence)\n",
        "#         lstm_out, h = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "#         lstm_out = lstm_out.contiguous().view(-1,self.hidden_dim)\n",
        "#         tag_space = self.hidden2tag(lstm_out)\n",
        "#         tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "#         return tag_scores[-1]\n",
        "#     def init_hidden(self,batch_size):\n",
        "#         device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#         weights = next(self.parameters()).data\n",
        "#         h = (weights.new(1, batch_size, self.hidden_dim).zero_().to(device),\n",
        "#              weights.new(1, batch_size, self.hidden_dim).zero_().to(device))\n",
        "        \n",
        "#         return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b56sE2abxtAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toTensor(inp):\n",
        "  return torch.tensor(inp,dtype = torch.long).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo1rC4CG_pez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.sample(frac=1)\n",
        "df2 = df2.sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz2-Tt65xvG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df['inp'].apply(toTensor).values\n",
        "Y_train = df['label'].apply(toTensor).values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xz_E-ZZ7Ri-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = df2['inp'].apply(toTensor).values\n",
        "Y_test = df2['label'].values\n",
        "Y_belongs = df2['y_belong']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH1uu-KB3nFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJRdnkKMx4Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inp = torch.tensor(df['inp'].head(1)[0],dtype = torch.long).to(device)\n",
        "# a = model(inp)\n",
        "# # make_dot(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4LQF-RW0A5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorboard --logdir logs/tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5I7BzO93mOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MvASl1DxxXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM_TE(EMBED_DIM, HIDDEN_DIM, VOCAB_SIZE, CLASS_SIZE).to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "optimizer = optim.Adagrad(model.parameters())#,weight_decay=1e-5)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMGFsN_6x5x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_list = []\n",
        "j = 0\n",
        "for epoch in range(60):\n",
        "  epoch_loss = 0 \n",
        "  for i in range(len(X_train)):\n",
        "    j += 1\n",
        "    x,y = X_train[i].to(device),Y_train[i].to(device)\n",
        "    model.zero_grad()\n",
        "    tg_score = model(x)\n",
        "    tg_score = tg_score.reshape((1,8))\n",
        "    y = y.reshape((1))\n",
        "    # print(tg_score)\n",
        "    # print(y)\n",
        "    loss = loss_function(tg_score,y)\n",
        "    epoch_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  # with train_summary_writer.as_default():\n",
        "  #       summary.scalar('loss', epoch_loss/len(X_train), step=epoch)\n",
        "  # if ( epoch % 10 == 0):\n",
        "  loss_list.append(epoch_loss/len(X_train))\n",
        "  # def animate(i):\n",
        "  #   ax1.clear()\n",
        "  #   ax1.plot(range(epoch+1),loss_list)\n",
        "  # ani = animation.FuncAnimation(fig, animate, interval=1000)\n",
        "  # plt.show()\n",
        "  print(\"Epoch [%d] %.6f \"%(epoch,epoch_loss/len(X_train)))\n",
        "  epoch_loss = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5xi4Nsejtim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(len(loss_list)),loss_list)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12XUL8TB0J6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_pred = torch.randn((len(X_test),8)).to(device)\n",
        "# for i in range(len(X_test)):\n",
        "#   print(model(X_test[i].to(device)).shape)#.reshape(1,8)\n",
        "#   break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ7CXbwB3b9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df2['inp']\n",
        "labels = {0: 'Potential_Threat_Anxiety_',\n",
        " 1: 'Frustrative_Nonreward',\n",
        " 2: 'Sustained_Threat',\n",
        " 3: 'Sleep_Wakefulness',\n",
        " 4: 'Circadian_Rhythms',\n",
        " 5: 'Arousal',\n",
        " 6: 'Loss',\n",
        " 7: 'Acute_Threat_Fear'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmvx_j2r0TJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdf = df2.groupby('label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1GQncTa17DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gdf.groups\n",
        "construct_test = {}\n",
        "for i in range(8):\n",
        "  construct_test[i]= df2.iloc[gdf.groups[i]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO23zkoD1FNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y_pred = y_pred.cpu().detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfwg0VxO0_GE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y_belongs = np.array(Y_belongs).reshape((len(Y_belongs),1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkDk_kaQ1ein",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y_test = np.array(Y_test)*np."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Qbe6fw0vdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.concatenate((Y_pred,Y_belongs),axis =1).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP8F5X0F1VOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy_score(Y_test, Y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hszSVJy31Wys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ap(y_pred,y_belong):\n",
        "  y_pred = np.array(y_pred)\n",
        "  y_belong = np.array(y_belong)\n",
        "  y_pred = y_pred.reshape(-1,1)\n",
        "  y_belong = y_belong.reshape(-1,1)\n",
        "  arr = np.concatenate((y_pred,y_belong),axis=1)\n",
        "  \n",
        "  arr = sorted(arr,key = lambda x:x[0],reverse=True)\n",
        "  \n",
        "  ans = 0\n",
        "  rel = 0\n",
        "  num = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    if arr[i][1] == 1:\n",
        "      rel = rel+1\n",
        "      ans += rel/(i+1)\n",
        "      num = num+1\n",
        "  return ans/num\n",
        "\n",
        "def map(y_pred,y,y_belong):\n",
        "  j = 0\n",
        "  j_prev = 0\n",
        "  ans = 0\n",
        "  for i in range(8):\n",
        "    while j<len(y) and y[j] == i:\n",
        "      j = j+1\n",
        "    ans = ans + ap(y_pred[j_prev:j],y_belong[j_prev:j])\n",
        "    j_prev = j\n",
        "  return ans/8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TsN9ddBqGya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or0nWhmqb_r-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "map_list = []\n",
        "class_count = {}\n",
        "for _ in range(1):\n",
        "  aps = 0\n",
        "  for cl_ in construct_test.keys():\n",
        "    X_test = construct_test[cl_]['inp'].apply(toTensor).values\n",
        "    y_pred = torch.randn((len(X_test),1)).to(device)\n",
        "    class_count[cl_] = len(X_test)\n",
        "    for i in range(len(X_test)):\n",
        "      y_pred[i] = model(X_test[i].to(device))[cl_,0].reshape(1,1)\n",
        "    y_pred = y_pred.cpu().detach().numpy()\n",
        "    # print(y_pred.shape)\n",
        "    y_belongs = np.array(construct_test[cl_]['y_belong'].values).reshape(len(X_test),1)\n",
        "    # print(y_belongs.shape)\n",
        "    # print(np.concatenate((y_belongs,y_pred),axis =1 ))\n",
        "    t = ap(y_pred,y_belongs)\n",
        "    print(labels[cl_],t)\n",
        "    aps += t\n",
        "  # println()\n",
        "  map_list.append(aps/8)\n",
        "  # break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEcdv6gXrj-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(class_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLybxKGNcJA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(sum(map_list)/len(map_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgYRv-dKEMy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(list(model.parameters()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqpvQnEt-uLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for parameter in model.parameters():\n",
        "  print(parameter.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNMbutdF6C5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}