{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('all')# download nltk files\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torchnlp.nn as nlp_nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "torch.manual_seed(1)\n",
    "# from tensorflow import summary\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap(y_pred,y_belong):\n",
    "  y_pred = np.array(y_pred)\n",
    "  y_belong = np.array(y_belong)\n",
    "  y_pred = y_pred.reshape(-1,1)\n",
    "  y_belong = y_belong.reshape(-1,1)\n",
    "  arr = np.concatenate((y_pred,y_belong),axis=1)\n",
    "  \n",
    "  arr = sorted(arr,key = lambda x:x[0],reverse=True)\n",
    "  \n",
    "  ans = 0\n",
    "  rel = 0\n",
    "  num = 0\n",
    "  for i in range(len(y_pred)):\n",
    "    if arr[i][1] == 1:\n",
    "      rel = rel+1\n",
    "      ans += rel/(i+1)\n",
    "      num = num+1\n",
    "  return ans/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_stop(txt):\n",
    "  return [ c for c in txt if c not in stopwords.words(\"english\")]\n",
    "stemmer = PorterStemmer()\n",
    "def word_stemm(txt):\n",
    "  return [stemmer.stem(w) for w in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_files_train = glob.glob(\"./dataset/Task1/Train/*.xlsx\")\n",
    "xl_files_test = glob.glob(\"./dataset/Task1/Test/*.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dataset/Task1/Test/Loss.xlsx',\n",
       " './dataset/Task1/Test/Frustrative_Nonreward.xlsx',\n",
       " './dataset/Task1/Test/Sleep_Wakefulness.xlsx',\n",
       " './dataset/Task1/Test/Sustained_Threat.xlsx',\n",
       " './dataset/Task1/Test/Potential_Threat_Anxiety.xlsx',\n",
       " './dataset/Task1/Test/Circadian_Rhythms.xlsx',\n",
       " './dataset/Task1/Test/Arousal.xlsx',\n",
       " './dataset/Task1/Test/Acute_Threat_Fear.xlsx']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xl_files_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "labels = {}\n",
    "revLabels = {}\n",
    "for i,xl in  enumerate(xl_files_train):\n",
    "    className = xl.split(\"/\")[-1][:-5]\n",
    "    labels[className] = i\n",
    "    revLabels[i] = className"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataframes\n",
    "frames = []\n",
    "for xl_file in xl_files_train:\n",
    "    df1 = pd.read_excel(xl_file)\n",
    "    className = xl_file.split(\"/\")[-1][:-5]\n",
    "    df1['Y'] = labels[className]\n",
    "    frames.append(df1)\n",
    "df_train = pd.concat(frames,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataframes\n",
    "frames = []\n",
    "for xl_file in xl_files_test:\n",
    "    df1 = pd.read_excel(xl_file)\n",
    "    className = xl_file.split(\"/\")[-1][:-5]\n",
    "    df1['Y'] = labels[className]\n",
    "    frames.append(df1)\n",
    "df_test = pd.concat(frames,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNC_LIST = string.punctuation + string.digits\n",
    "TOKENIZER = re.compile(r\"\\w+\")\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        Removes non-alphabetic characters\n",
    "    \"\"\"\n",
    "    #remove new line and carriage with space\n",
    "    text = text.replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
    "    tmp = str.maketrans(dict.fromkeys(PUNC_LIST,\" \"))\n",
    "    text = text.translate(tmp)\n",
    "    # replace single quote with empty \n",
    "    tmp  = str.maketrans(dict.fromkeys(\"'`\",\"\"))\n",
    "    return text.translate(tmp)\n",
    "def regexTokenize(text):\n",
    "\n",
    "    return TOKENIZER.findall(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre process the text\n",
    "stop_words = stopwords.words(\"english\")\n",
    "def stem(w):\n",
    "#     return w.lower()\n",
    "    return stemmer.stem(w)#.lower()\n",
    "cols = ['title','abstract']\n",
    "for col in cols :\n",
    "    df_train['c_'+col] = df_train[col].apply(lambda x: \" \".join([stem(i) for i in regexTokenize(x) if i not in stop_words]))\n",
    "    df_test['c_'+col] = df_test[col].apply(lambda x: \" \".join([stem(i) for i in regexTokenize(x) if i not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the entire text\n",
    "df_train['inp'] =  df_train['c_title'] + df_train['c_abstract']\n",
    "df_test['inp'] = df_test['c_title']  + df_test['c_abstract']\n",
    "# c_title = df_train[['c_title','pmid']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train['inp'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()#, tokenizer=regexTokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pmid', 'title', 'abstract', 'Belongs to RDoC construct?',\n",
       "       'Relevant Context', 'Y', 'c_title', 'c_abstract', 'inp', 'Belongs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency analysis\n",
    "voc = {}\n",
    "for row in x_train:\n",
    "    for w in row.split():\n",
    "        if w in voc : \n",
    "            voc[w] += 1\n",
    "        else:\n",
    "            voc[w] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep 513\n"
     ]
    }
   ],
   "source": [
    "freqList = []\n",
    "v= 1000\n",
    "label = []\n",
    "for k in voc.keys():\n",
    "        freqList.append(voc[k])\n",
    "        label.append(k)\n",
    "        if voc[k] > 400:\n",
    "            print(k,voc[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x132f86e50>]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3de3gV5b0v8O9PFC/VCihSDmCjp2zd7N1WKdtitX0UbwjuarvV2l0r2+PZHLe2tVprUU89u/Qi1jtVqygqYlUQpSCIghDkHggQbuGSAIEkBBJyjyEhl9/5Y70rWVmZdctak1nzru/neXgy885k1ruGrO+86513ZkRVQUREdjnB6woQEVHqMdyJiCzEcCcishDDnYjIQgx3IiILneh1BQDg7LPP1qysLK+rQUTkKxs3bjyqqgOdlqVFuGdlZSE3N9frahAR+YqIHIi0jN0yREQWYrgTEVmI4U5EZCGGOxGRhRjuREQWYrgTEVmI4U5EZCGGe4p9sr0MRxuava4GEWU4hnsK1TW14O63N+E/3ljvdVWIKMMx3FOorS3w4JOS6mMe14SIMl1c4S4iRSKyTUTyRCTXlA0QkSUiUmB+9jflIiJTRaRQRLaKyEg33wAREXWXSMv9SlW9SFVHmflJAJaq6nAAS808AFwPYLj5NxHAX1NVWSIiik8y3TI3AphhpmcAuCmk/C0NWAegn4gMTuJ1iIgoQfGGuwJYLCIbRWSiKRukqmVm+jCAQWZ6CIDikN8tMWVdiMhEEckVkdyKiooeVJ2IiCKJ95a/l6tqqYicA2CJiOwKXaiqKiKayAur6jQA0wBg1KhRCf0uERFFF1fLXVVLzc9yAHMBXALgSLC7xfwsN6uXAhgW8utDTRkREfWSmOEuIl8SkTOC0wCuBbAdwHwAE8xqEwDMM9PzAdxhRs2MBlAb0n1DRES9IJ5umUEA5opIcP13VPUTEdkAYLaI3AXgAIBbzfofAxgHoBBAI4A7U15rIiKKKma4q+o+AN90KK8EcJVDuQK4NyW1IyKiHuEVqkREFmK4ExFZiOFORGQhhjsRkYUY7kREFmK4ExFZiOFORGQhhjsRkYUY7kREFmK4ExFZiOHuAuUNjInIYwx3IiILMdxdELiBJhGRdxjuREQWYrgTEVmI4U5EZCGGOxGRhRjuREQWYrgTEVmI4U5EZCGGOxGRhRjuREQWYrgTEVmI4U5EZCGGOxGRhRjuREQWYrgTEVmI4U5EZCGGOxGRhRjuREQWijvcRaSPiGwWkQVm/jwRyRGRQhGZJSJ9TfnJZr7QLM9yp+pERBRJIi33+wDsDJl/AsCzqvo1ANUA7jLldwGoNuXPmvWIiKgXxRXuIjIUwHgAr5l5ATAGwByzygwAN5npG808zPKrzPqUhtburUTR0S+8rgYRpVi8LffnADwEoN3MnwWgRlVbzXwJgCFmegiAYgAwy2vN+l2IyEQRyRWR3IqKih5Wn5L141fX4YqnlntdDSJKsZjhLiI3AChX1Y2pfGFVnaaqo1R11MCBA1O5aSKijHdiHOtcBuD7IjIOwCkAvgzgeQD9RORE0zofCqDUrF8KYBiAEhE5EcCZACpTXnMiIoooZstdVR9W1aGqmgXgNgDLVPUnALIB3GxWmwBgnpmeb+Zhli9TVU1prYmIKKpkxrn/BsADIlKIQJ/6dFM+HcBZpvwBAJOSqyIRESUqnm6ZDqq6HMByM70PwCUO6zQBuCUFdSMioh7iFapERBZiuBMRWYjhTkRkIYY7EZGFGO7kuaxJC/H7BfleV4PIKr4P980Hq5FXXON1NShJ01ft97oKRFZJaChkOvrBS2sAAEVTxntcEyKi9OH7ljsREXXHcCcishDDnYjIQgx3IiILMdyJiCzEcCcishDDnYjIQgx3IiILMdyJiCzk+ytUyb9UFU8v3uN1NYisZE3LfebaIq+rQAmqO9aKF7ILva4GkZWsCfffztvhdRWIiNKGNeFORESdrA338vomXPvs5yipbvS6KkREvc7acJ+7qRR7jjTgrbUHvK4KRSJeV4DIXtaGOxFRJrM+3FXV6yoQEfU6a8Nd+JWfiDKYteEexIY7EWUia8NdeLaOiDKYVeHe1t7ZTFewyU5EmcuqcL/55TVeV4ESwPMiRO6JGe4icoqIrBeRLSKyQ0R+Z8rPE5EcESkUkVki0teUn2zmC83yLHffQqfNB2s6681uGSLKYPG03JsBjFHVbwK4CMBYERkN4AkAz6rq1wBUA7jLrH8XgGpT/qxZzzOp6pypb2rBmsKjKdoaEZG7Yoa7BjSY2ZPMPwUwBsAcUz4DwE1m+kYzD7P8KpHe/wKe6lf8xbub8e+v5aCivjm1GyYickFcfe4i0kdE8gCUA1gCYC+AGlVtNauUABhipocAKAYAs7wWwFkO25woIrkikltRUZHcu4giVUMh9xwJHN+aW9tSs0EiIhfFFe6q2qaqFwEYCuASABcm+8KqOk1VR6nqqIEDBya7uQ6Nx1tjr0REZLmERsuoag2AbACXAugnIsEnOQ0FUGqmSwEMAwCz/EwAlSmpbRz+6+1NXeZT3T3Di6KIyA/iGS0zUET6melTAVwDYCcCIX+zWW0CgHlmer6Zh1m+THvxBi/r91d1mWcYE1EmiucZqoMBzBCRPggcDGar6gIRyQfwnoj8AcBmANPN+tMBzBSRQgBVAG5zod5pjQeU+HCwKpF7Yoa7qm4FcLFD+T4E+t/Dy5sA3JKS2qUAr1Qlokxk1RWqoTwYfRny2p69NBERAAvDPbylzi4SIspE1oU7ERFZGO7h95RJVRcJu1qIyE+sC/dw7JYhokxkbbi71dDmwSJ1vDzpTWQ768KdQx+JiCwM9yC3GoVsbBKRH1gX7sETquw+IaJMZl24uy2egwYPLETkNWvDPdXdJ+yOISI/sS7cu1+h2vvNaB4IiMhr1oV7EPOViDJZPLf89TV2f6enmsbjHOdO5CLrwj04WobBkb5qG1tw0eQl+Mm3z/W6KkTWsrZbxq2+dl4klbyaY8cBAIu2H/a4JkT2si7c3Qrf8BuSERGlM+vCPYjdMunPi5FMRJnC2nAPYn6kH34LInKfteG+Zu9Rr6tAROQZ68JdINhaUoNPdxzxrA78tkBEXrMu3BWKyobj7m0/SnDblum/fG8zZqwp8roaRNQD1oW7WxI5P2vLudy/5x3C/5u/w7Xt23YwJEon1oc7x6Wnn+DBj91XRO6xMtzdDHTmUfIY6kTuszLcQzFIiCgTWRfubo+htqQ73VO2nJMgSmfWhbvbfez8IpA6vEKVyD3WhTvArhgiIivD3Q3sSUg9HoOJ3BMz3EVkmIhki0i+iOwQkftM+QARWSIiBeZnf1MuIjJVRApFZKuIjHT7TUQTT4BU1De7Xg8iot4UT8u9FcCvVHUEgNEA7hWREQAmAViqqsMBLDXzAHA9gOHm30QAf015raMQSELdMnnFNfiXP36GDzaWpKwO7BYiIq/FDHdVLVPVTWa6HsBOAEMA3AhghlltBoCbzPSNAN7SgHUA+onI4JTXPFJ9uz0gO/r6uw/XAQB+9f4WbC2pSe61mepElCYS6nMXkSwAFwPIATBIVcvMosMABpnpIQCKQ36txJSFb2uiiOSKSG5FRUWC1XbH919YnZLtcKhfnHgsJHJN3OEuIqcD+ADAL1W1LnSZBpqsCX1UVXWaqo5S1VEDBw5M5FcTtn5/FV7MLnRclui4eLbOk8eDH5H74gp3ETkJgWD/m6p+aIqPBLtbzM9yU14KYFjIrw81Zb0mPH5vfWUtnvx0d1Lb5JOdiMhP4hktIwCmA9ipqs+ELJoPYIKZngBgXkj5HWbUzGgAtSHdN77S2taO7N3lsVckIkoz8bTcLwPwUwBjRCTP/BsHYAqAa0SkAMDVZh4APgawD0AhgFcB3JP6aiei590oL2QX4s43NmDFns5zAuyUSR3uSyL3nBhrBVVdhcjX8FzlsL4CuDfJeiUloX7xKL0tByobAQBHGzgO3g08f0HkHuuvUE1FfoRugz3vyeP5CyL3WR/u720ojr1SBE4RZHtbc0NRFTYUVbn6GmyxE7kvZreMH7kRHZnS1rzl5bUAgKIp4z2uCRElw/qWeyxuhDYbptGxW4bIfRkV7k8v3o0pi3Z1KYsnh0PXiRbczPTEcH8RuSejwv0vywrx8ud7XX8dNkyjC+4efsMhco+V4Z7MSMhYJ/sY3MljphO5z8pwT8amgyF3hnQIcrY2icgPGO5hmlraupWpauYMl+kF3JVE7rM03Nm89gO3H2ZOlMksDff4cVhe7+MuJ3JfRob7kvwjKKs9FnM953u9s7WZLJ63IHJfRob7f76Vi5tejP+pS8wiIvIb68JdNb6W4ZE65zs9xu4xYJ9CsoLdMmzBE7nHunAHEmtp1x1rSfnWGVpE5DXrwj3Rk3WTF+THta14NstQTwx3F5F7rAv3dOCX0SA/emWt11UgIpcw3BNkU+s8Z7+7920nIu9YF+6uhK9FgZ4OnIeYElEqWRfuqeQUQX7pcvEFHjSJXGNduDe3tqOtPYnUiBHeNnXLeI23HyByj3XhDgQeytFjEfIm0dsUbCupxe7D9T2vh8X47YfIfVY+Q7WosjGl24vWwmxobsUTi3bh8uFndwnzf31hVaAufBZpN/z2Q+Q+K8M9KaFj253u5x42//LyvZi57gBmrjvgarWIiBJhZbdMb2pzaIayZdozFfXNyD9U53U1iKyQ0eFe03g84d9hd3HqhB8Exzy9HOOmrvSmMkSWyehwf2TutrjWCw0hNspTJ3xf1je1elIPIhtldLg3NHd/pF4kibTYORokOg6BJHJfRoe7Wt453tLWjta2dq+rQUQeyOhwj8XpMnk/HQ+GP7oIY57+3OtqEJEHYoa7iLwuIuUisj2kbICILBGRAvOzvykXEZkqIoUislVERrpZeTc4Bjr829VysCq1Y/6JyB/iabm/CWBsWNkkAEtVdTiApWYeAK4HMNz8mwjgr6mpprMDlV8k9ftOrXCFYtPBatz+Wg4+2XE46rqUHNu7xYi8FDPcVXUFgPB7w94IYIaZngHgppDytzRgHYB+IjI4VZUN99xnBa5s98HZW7Cq8ChqHZ7S5NcWfDphphO5r6d97oNUtcxMHwYwyEwPAVAcsl6JKetGRCaKSK6I5FZUVPSoEsm2/JxGbcS6HS2DiR7+cCv+e/4Or6tBFFXSJ1Q1kLAJR56qTlPVUao6auDAgclWo0ciBnVYvqsm1mKvaUz0uayZya/HyXfXF+PNNUVeV4Moqp6G+5Fgd4v5WW7KSwEMC1lvqClzhRfhUN14HO3J3FKYKIbJH+Xj2mc5yomS09Nwnw9ggpmeAGBeSPkdZtTMaAC1Id03KbcjyfuQRGq5R2uk3zZtHV5aXhj3a2TvKo+9UoZiF5ez11fvx54jDV5Xg3wunqGQ7wJYC+ACESkRkbsATAFwjYgUALjazAPAxwD2ASgE8CqAe1yptVFY7s0H4KnFe/DM4t1xteDvfHMDPt/Ts3MKtmKmp87x1naU1hzzuhqUhmLe8ldVfxxh0VUO6yqAe5OtVG+JNAY8ngdzTF1WiJFf7R/X61R90ZxQvTKFCFvvyfrNB1sxd3Mpdk4ei1P79vG6OpRGMvoKVacWz0vLC+P+RtDaFl8yFfArtiMGe/KWmW6/5tb475NEmSGjw93JyoKj3coUGnOIZDQvLd+LphZ3Pnzv5BxE9ReJ37qY7BD8kskDJYVjuMdhwZYy7D7S/Xmom4ur495GqwsjbHaW1eGRudtw/+y8pLfFq0X9jf97FM7X4T7+G65d/NrF2n2VjuUvZu+Nexvh7f6S6uTv+dLcGrjjY2n1MVQl2XpvaO69e6nHeyBpaWtH1qSFeH3Vfpdr5F/BvysenCmcr8P9J5ec63UV4hb60Vu7txKXP5GNrEkLsbOs58M5gx/ogvIGjPz9kiRrmH4azf32n/tsj8c1SV/xnPynzOTrcPfrH/aekC6e3gqud3IOYpXD+YR09ceF+fjm5MVeVyPtdbTcPa0FpaOYQyHTmZ+yPbSqofVO5kRtIh/o4CMFi6aMd1ze3NqOM3pck9R7dSW7YuLBE6oUia9b7if4Kd0jSOYtpPIDPeoPn6VuY9SLAn9AfHQhhfN1uKdDtvckYCO14mOpbGjGK5/vTfuTZ8eOt6GmMfIJ3jSvvq8I+2UoAn+Hu9cVAJCz33kkTVQhiZ5It8yD72/B44t2Ia+4xpT0/BO9urB7//sn2w87rJm4cVNX4qLJdpzgPVzbhBv+shLldU2uvo6q4uNtZWhzGDLb2taO26atRU6EUVsAs52683e4p0HTffPBmtgrhZm5tqhjeuG2MmRNWhi1pRtU3xQYrhgcM59MC3h7aW23srvf3tjzDYbYfzS5J2Slk5nrirC9tA6zNhTHXjkJf88rxT1/2+Q47PNQTRPW7avCr97f0m1Z51BIV6tHPuTzcPe6BvELfvYeX7TT8Y5/6/ZV4YonszEvL/YdklPxQQ6OkU9HeyvS53YN0tGn7a6j9YGD+xGHbwjB/nSnv/fe+gzkFlXh4smLHZ9ORunJ1+HuxxOqr3y+z7H87rc3oqiyEb+esxX5h+rw6Nxt2FLc9VtB58gI03IP28a+OEOxuKoRzyyJPgTTqXugt1z1dOL3Mj9UcwzFLjwMPB1GowRf26kLL1jW7lIF29oVG4qq8PzSAlQ3tmDzwfivyiZv+Trc/RTtcZ8E1UCf9d9yDuLGF1d3WRT+4Q7f5JiQUKxs6LwT5c/f3dxlvX1xdJskc3FVqjl1v7W0tXe5p853pizDd/+cnfrXTvkWey5ayz34p6CqmL5qf9JXLAe9lF2IW15eiw1F4Y9RpnTn73BPp09eDHe/vTGugA8f0rZ4x2HcPysPKwsqOm4REGsrtY0t+FbI0MaPthzqsvyT7bGfn5Ku+3ZJ/hHcPysPD8zegot78apcL4caRnvl4LfX4N/WttJa/H5BPh506J/vieA9lZpa2mPWhdKLvy9iSqt2VXSrCytx3sMfx1wvvDtk4szASc65mzv74oPHiEgHi5pj0VttG4r8+9X6P9/K7TKvqu6eWO8IT/deIpLgewv+P0d7l8H6tbQFQjieE/Q9rRP5A1vuaSaeru5gKzLSqi9/Hv8NzXqqta09LT7obp8a8HIYeXCETvC1nQ5i3c8JuHsCOA3+yylOvg73TBfpg/bu+ujD9iI9gSoe5fVNyD9Uh689uggvLe88iDQ0t2L34e63RQaAORtLMD+sa6gnnEbRuHUiMUg8HGu4paS2y0s7tWWC9QvuB7dPADPc/cPX4W5jyz0eD3+4De3t6jgs7Tdztsb8/eNJDIO85I9LMW7qSgDoMvb7zjfW47rnVjj+zoPvb8Evwk7q9kS+wwPRXQ93D7v+un0zcqhKsM+9PY6um0Qdb23v1VtBU2r5us89Ux2obMQTn+zCKyu6D6uclRu91V7XlLpxyqEnGYP9+HGdNE4wj4MHMaeDeW+1JN1+mT9+vLNbWeeBK/KrB3dJePdUKup7+/QcrN/fdZQMG+7+4etw99MJ1VTraTfH/Lzku0eimbOxxJXtZk1a6FjeW90yXhxEZueWIOvsL+GafxwUqIvD+hI2WkZSWOHwYA99HUp/7JbxqZ5+xuL9cC7fXdGtLNKFTct3l3dM/zqObqFUiueEakNzK8Y8vRxbSxK7VcTy3eUdF3slMxRy7d7KqBdYRfs/ee6zgugnVM3P9rB+eddOqLq0XUo9hrtPtfUw3d9cUxTXek9+urtjOhhMDU1d+1+Lq47h/dxi/McbGyJup7TmWOKVTMAXDn3Cuw/Xd3kg+X3vbsa+ii863lNza1tcF2mFHqii7e7qL47jYGXk8P7xq+uiXmAVeoAK/5M+QSKfUB3x2CcdF6SF36Ig1p9H1qSF+NEra6Ov5CDadg/VHMPvPtrh6dXN1Mnf4Z7B3TIV9c2xV3KwtyLxm3p998+BRwI6PRkpWkt9e2ktLpuyLOHXS0TwOoCguqYWXPfcCkyc2XnR2NJdgW8Wwfu2/Pf8Hbj++ZUormrsOAjc+vJa/Cms3zs0yKLF1RVPLcf3nuwa3rNzi1FR3xzXCcloLfemlnbkHgh0j4Rfddp4vPMA1m7OkXfeCyd2wOY4dLsk48H3t+CN1UXI5dWsacHXfe6U3m74yyrH8lRe7bmluAZjQ0bpNJsrKVfsqcDMdQdwx6VZHcvqm1rReLy1Y6hosDVdNGU81hdVYX1RFR4Z949dahqqpvE4Dji00MNHLZXVHsNDc7bin4d8GdtLu35DKDIt7ayzv4Rdh+vQ79S+GPClvlHf4x8WBA46lVFuKdBbQyGjHeaCdWDDPT34u+WeuQ13X/qH/7vIle3uChlfP21F59j7xTuOdFmvrLYJIx77tEevoRpooYfe76elrb3bXRzb2hXFVYGuqJLq7l1SVzy1HFc8tRwAMPa5lbh0ytKYXVfHQrqYIqlrakFtY+dBxotx7uHDMoOO1DXF/ZCZ0ppjXdar/uI4siYtxMKtsW+ZEZS9qxwr9lRgdm5xWtwj6aLJi/HYvO29/rr+DnevK0AJCY6vz3Xx9gehz1491tKG7zy+NObvhF8cVd/Ugg83leBoQ2dLuaK+GTWNXVvowx9dhG//qev2n19agFtNX3a0v88dhzovULrShD3Q8xOW//5qDr45eXFHgye/rA5NLW34wUursfFA5P0d+myBUCsLup9QB4AVBRX40StrHfvVQ8O9qaWt4x5GP39nMx5ftAubzB0lC8vrsa2k+/ME8g/V4bIpy/DW2gMdZYXm/+b11fE/U/fONzfgjtfX46E5W3H98yvj/r1UK69vwsqCCtQ0tnR5T73F3+HOdPedj7YccnzohBs2HqjGodrYT1DaGHaw+dXsLXhgdtc6xnOP+axJCzF1aUHHfHgAtofMj5/q3GUVS1NLGwrLI9cl9DxUYXkDNh+swW//3rXVGDqs9LfzdqC2sQUl1Y2oqG9GeV0TahqP46fT1ztu/931xcjZX4X/+cjHWLGn8wDQ1NKGVebpXm3tiskL8nH325tw+2s5WG/64Ce+FTg/cvUzK/CvL3R//werAl1Wa/Z2PiUs2tW5QZUNzTgcx/9zvFQVT3262/GhM5sOViNr0sKOA1U0d0xfH3E/9gaf97kz3f0m/PbD6eChDzpPCm88UI3F+Ue6rZNXnPgTt5rCrgQ+/5HYN46b7vAkplAX/vYTAEDfPs7tstkhF7EFn+qUX1aHJz/dhV9fd6Hj6KKrn/28ywn6PifE97m64/X1eOWn38J1//SVLlcrz1x7oOOpYatCHucYfs7gg40l+M7XzsLgM08F0NnyN/c+w+wNxR3/N7kHqlFc1Yhxz6/E3HsvQ//TTsLy3RVoam3Do3MDB6+iKeMj1rW+qQXz8g6hqaUNt4/+KsZPXYmJ3zsfn++pQL/T+uKmi4bg1lfWYvqEUfjnIWfihexCvJBdiCsuGIg377ykYzsr9wTezw9fWoOVD12JYQNOi/iaTgeH2sYWnNL3BJx8Yh+0tLWjXRUnn9gn4jaS4Uq4i8hYAM8D6APgNVWd4s7ruLFVymT/9tc1KdtWMrd5iLntNudthw51/TDkTqIvZu9FXnENVhd2fw5r+MirRIYy/p+Z3R/NGByd5KSstvP8QvAb3OpJYzCk36kdI7naVdHQ3NrloBtcv765Fe/kHMTuI3Xd3svOsrqI3TC/X5CP2bmBC+z+sDBwgvo3H2zrWP5OzkEAwF0zcnH/1f/QUR5+vceJfTpD57t/zsaFXzkDuw7XY/w3BuNA5RfYXlqH9+++FP+SNQAn9TmhyxPPSqobcfkTgZP4v77uAszaUIyDVY1RD0rJkFRfcSYifQDsAXANgBIAGwD8WFXzI/3OqFGjNDc3N9LiiPZVNHR5QAURUbjr/mkQPt3R/dtYvG666H/gygvPwawNxVizN/JDyntq/+PjenzbahHZqKqjnJa50ed+CYBCVd2nqscBvAfgRhdeB6ef4vNeJSJyXTLBDgB/zzuE+97LcyXYgdhdcT3lRrgPARB696oSU9aFiEwUkVwRya2ocD4zH8s5Z5yC+64ajsduGIHT+vbBQ2Mv6Fi28BeXY8HPLwcAfPSzy/HANYGvWldeMBBbHrsW478+GLePPrfL9sLHG//pB1/vmB585in4+Bff7Zi/ffS5uOVbQzH3nu/g/bsvxZ2XZQEAzh1wGn559XCM+/pX8NgNI3r0vgBgyg87X3vkuf26LDv5xBMijo0+qY/g3Cj9gEHDBgT6OYefczp+OHII/m3k0B7X1Q1L7v8efjhyCMZceA6uGRG4t8olWQMirj/oyyf3VtWIUmr4oDNc2a4b3TI3Axirqv/bzP8UwLdV9WeRfqen3TJERJmst7tlSgEMC5kfasqIiKiXuBHuGwAMF5HzRKQvgNsAzHfhdYiIKIKUn5FU1VYR+RmATxEYCvm6qu5I9esQEVFkrgw3UdWPAcS+YoOIiFzh69sPEBGRM4Y7EZGFGO5ERBZiuBMRWSjlFzH1qBIiFQB6esPjswEcjblW5uF+iYz7xhn3i7N03i9fVdWBTgvSItyTISK5ka7QymTcL5Fx3zjjfnHm1/3CbhkiIgsx3ImILGRDuE/zugJpivslMu4bZ9wvzny5X3zf505ERN3Z0HInIqIwDHciIgv5OtxFZKyI7BaRQhGZ5HV93CYir4tIuYhsDykbICJLRKTA/OxvykVEppp9s1VERob8zgSzfoGITPDivaSSiAwTkWwRyReRHSJynynP6H0jIqeIyHoR2WL2y+9M+XkikmPe/yxza26IyMlmvtAszwrZ1sOmfLeIXOfNO0otEekjIptFZIGZt2u/qKov/yFwO+G9AM4H0BfAFgAjvK6Xy+/5ewBGAtgeUvZnAJPM9CQAT5jpcQAWARAAowHkmPIBAPaZn/3NdH+v31uS+2UwgJFm+gwEHtA+ItP3jXl/p5vpkwDkmPc7G8BtpvxlAP9lpu8B8LKZvg3ALDM9wny+TgZwnvnc9fH6/aVg/zwA4B0AC8y8VfvFzy33XnsQd7pQ1RUAqsKKbwQww0zPAHBTSPlbGrAOQD8RGQzgOgBLVLVKVasBLE6Ri7oAAAJQSURBVAEw1v3au0dVy1R1k5muB7ATgef2ZvS+Me+vwcyeZP4pgDEA5pjy8P0S3F9zAFwlImLK31PVZlXdD6AQgc+fb4nIUADjAbxm5gWW7Rc/h3tcD+LOAINUtcxMHwYwyExH2j9W7zfzlfliBFqpGb9vTNdDHoByBA5WewHUqGqrWSX0PXa8f7O8FsBZsHC/AHgOwEMA2s38WbBsv/g53CmMBr4rZuzYVhE5HcAHAH6pqnWhyzJ136hqm6pehMCzjC8BcKHHVfKciNwAoFxVN3pdFzf5Odz5IO6AI6ZLAeZnuSmPtH+s3G8ichICwf43Vf3QFHPfGKpaAyAbwKUIdEMFn8IW+h473r9ZfiaASti3Xy4D8H0RKUKgO3cMgOdh2X7xc7jzQdwB8wEER3VMADAvpPwOMzJkNIBa00XxKYBrRaS/GT1yrSnzLdP/OR3ATlV9JmRRRu8bERkoIv3M9KkArkHgfEQ2gJvNauH7Jbi/bgawzHzjmQ/gNjNq5DwAwwGs7513kXqq+rCqDlXVLARyY5mq/gS27Revz+gm8w+BUQ97EOhHfNTr+vTC+30XQBmAFgT69+5CoO9vKYACAJ8BGGDWFQAvmn2zDcCokO38LwRO/hQCuNPr95WC/XI5Al0uWwHkmX/jMn3fAPgGgM1mv2wH8JgpPx+BECoE8D6Ak035KWa+0Cw/P2Rbj5r9tRvA9V6/txTuoyvQOVrGqv3C2w8QEVnIz90yREQUAcOdiMhCDHciIgsx3ImILMRwJyKyEMOdiMhCDHciIgv9f9sWsBy3RggDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(freqList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tfidf.fit_transform(x_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test['inp'].values\n",
    "x_test = tfidf.transform(x_test).toarray()\n",
    "df_test['Belongs'] = df_test['Belongs to RDoC construct?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.groups\n",
    "gdf = df_test.groupby('Y')\n",
    "construct_test = {}\n",
    "for i in range(8):\n",
    "  construct_test[i]= df_test.iloc[gdf.groups[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = [28,21,48,18,27,47,38,39]\n",
    "ncw = [ np.exp(-(i/sum(cw))) for i in cw]\n",
    "tcw = [ np.exp((i/sum(cw))) for i in cw]\n",
    "sftmax = { i:e/ sum(ncw) for i,e in enumerate(ncw)}\n",
    "tsftmax = { i:e/ sum(tcw) for i,e in enumerate(tcw)}\n",
    "siminv={ i:e/ sum(cw) for i,e in enumerate(cw)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class XGBClassifier in module xgboost.sklearn:\n",
      "\n",
      "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
      " |  XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
      " |  \n",
      " |  Implementation of the scikit-learn API for XGBoost classification.\n",
      " |  \n",
      " |      Parameters\n",
      " |  ----------\n",
      " |  max_depth : int\n",
      " |      Maximum tree depth for base learners.\n",
      " |  learning_rate : float\n",
      " |      Boosting learning rate (xgb's \"eta\")\n",
      " |  n_estimators : int\n",
      " |      Number of boosted trees to fit.\n",
      " |  silent : boolean\n",
      " |      Whether to print messages while running boosting.\n",
      " |  objective : string or callable\n",
      " |      Specify the learning task and the corresponding learning objective or\n",
      " |      a custom objective function to be used (see note below).\n",
      " |  booster: string\n",
      " |      Specify which booster to use: gbtree, gblinear or dart.\n",
      " |  nthread : int\n",
      " |      Number of parallel threads used to run xgboost.  (Deprecated, please use n_jobs)\n",
      " |  n_jobs : int\n",
      " |      Number of parallel threads used to run xgboost.  (replaces nthread)\n",
      " |  gamma : float\n",
      " |      Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      " |  min_child_weight : int\n",
      " |      Minimum sum of instance weight(hessian) needed in a child.\n",
      " |  max_delta_step : int\n",
      " |      Maximum delta step we allow each tree's weight estimation to be.\n",
      " |  subsample : float\n",
      " |      Subsample ratio of the training instance.\n",
      " |  colsample_bytree : float\n",
      " |      Subsample ratio of columns when constructing each tree.\n",
      " |  colsample_bylevel : float\n",
      " |      Subsample ratio of columns for each split, in each level.\n",
      " |  reg_alpha : float (xgb's alpha)\n",
      " |      L1 regularization term on weights\n",
      " |  reg_lambda : float (xgb's lambda)\n",
      " |      L2 regularization term on weights\n",
      " |  scale_pos_weight : float\n",
      " |      Balancing of positive and negative weights.\n",
      " |  base_score:\n",
      " |      The initial prediction score of all instances, global bias.\n",
      " |  seed : int\n",
      " |      Random number seed.  (Deprecated, please use random_state)\n",
      " |  random_state : int\n",
      " |      Random number seed.  (replaces seed)\n",
      " |  missing : float, optional\n",
      " |      Value in the data which needs to be present as a missing value. If\n",
      " |      None, defaults to np.nan.\n",
      " |  **kwargs : dict, optional\n",
      " |      Keyword arguments for XGBoost Booster object.  Full documentation of parameters can\n",
      " |      be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.md.\n",
      " |      Attempting to set a parameter via the constructor args and **kwargs dict simultaneously\n",
      " |      will result in a TypeError.\n",
      " |      Note:\n",
      " |          **kwargs is unsupported by Sklearn.  We do not guarantee that parameters passed via\n",
      " |          this argument will interact properly with Sklearn.\n",
      " |  \n",
      " |  Note\n",
      " |  ----\n",
      " |  A custom objective function can be provided for the ``objective``\n",
      " |  parameter. In this case, it should have the signature\n",
      " |  ``objective(y_true, y_pred) -> grad, hess``:\n",
      " |  \n",
      " |  y_true: array_like of shape [n_samples]\n",
      " |      The target values\n",
      " |  y_pred: array_like of shape [n_samples]\n",
      " |      The predicted values\n",
      " |  \n",
      " |  grad: array_like of shape [n_samples]\n",
      " |      The value of the gradient for each sample point.\n",
      " |  hess: array_like of shape [n_samples]\n",
      " |      The value of the second derivative for each sample point\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      XGBClassifier\n",
      " |      XGBModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  evals_result(self)\n",
      " |      Return the evaluation results.\n",
      " |      \n",
      " |      If eval_set is passed to the `fit` function, you can call evals_result() to\n",
      " |      get evaluation results for all passed eval_sets. When eval_metric is also\n",
      " |      passed to the `fit` function, the evals_result will contain the eval_metrics\n",
      " |      passed to the `fit` function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      evals_result : dictionary\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      param_dist = {'objective':'binary:logistic', 'n_estimators':2}\n",
      " |      \n",
      " |      clf = xgb.XGBClassifier(**param_dist)\n",
      " |      \n",
      " |      clf.fit(X_train, y_train,\n",
      " |              eval_set=[(X_train, y_train), (X_test, y_test)],\n",
      " |              eval_metric='logloss',\n",
      " |              verbose=True)\n",
      " |      \n",
      " |      evals_result = clf.evals_result()\n",
      " |      \n",
      " |      The variable evals_result will contain:\n",
      " |      {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      " |       'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None)\n",
      " |      Fit gradient boosting classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          Feature matrix\n",
      " |      y : array_like\n",
      " |          Labels\n",
      " |      sample_weight : array_like\n",
      " |          Weight for each instance\n",
      " |      eval_set : list, optional\n",
      " |          A list of (X, y) pairs to use as a validation set for\n",
      " |          early-stopping\n",
      " |      eval_metric : str, callable, optional\n",
      " |          If a str, should be a built-in evaluation metric to use. See\n",
      " |          doc/parameter.md. If callable, a custom evaluation metric. The call\n",
      " |          signature is func(y_predicted, y_true) where y_true will be a\n",
      " |          DMatrix object such that you may need to call the get_label\n",
      " |          method. It must return a str, value pair where the str is a name\n",
      " |          for the evaluation and value is the value of the evaluation\n",
      " |          function. This objective is always minimized.\n",
      " |      early_stopping_rounds : int, optional\n",
      " |          Activates early stopping. Validation error needs to decrease at\n",
      " |          least every <early_stopping_rounds> round(s) to continue training.\n",
      " |          Requires at least one item in evals.  If there's more than one,\n",
      " |          will use the last. Returns the model from the last iteration\n",
      " |          (not the best one). If early stopping occurs, the model will\n",
      " |          have three additional fields: bst.best_score, bst.best_iteration\n",
      " |          and bst.best_ntree_limit.\n",
      " |          (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n",
      " |          and/or num_class appears in the parameters)\n",
      " |      verbose : bool\n",
      " |          If `verbose` and an evaluation set is used, writes the evaluation\n",
      " |          metric measured on the validation set to stderr.\n",
      " |      xgb_model : str\n",
      " |          file name of stored xgb model or 'Booster' instance Xgb model to be\n",
      " |          loaded before training (allows training continuation).\n",
      " |  \n",
      " |  predict(self, data, output_margin=False, ntree_limit=0)\n",
      " |  \n",
      " |  predict_proba(self, data, output_margin=False, ntree_limit=0)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from XGBModel:\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  apply(self, X, ntree_limit=0)\n",
      " |      Return the predicted leaf every tree for each sample.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape=[n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      \n",
      " |      ntree_limit : int\n",
      " |          Limit number of trees in the prediction; defaults to 0 (use all trees).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      " |          For each datapoint x in X and for each tree, return the index of the\n",
      " |          leaf x ends up in. Leaves are numbered within\n",
      " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      " |  \n",
      " |  get_booster(self)\n",
      " |      Get the underlying xgboost Booster of this model.\n",
      " |      \n",
      " |      This will raise an exception when fit was not called\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      booster : a xgboost booster of underlying model\n",
      " |  \n",
      " |  get_params(self, deep=False)\n",
      " |      Get parameters.\n",
      " |  \n",
      " |  get_xgb_params(self)\n",
      " |      Get xgboost type parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from XGBModel:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array of shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=3, min_child_weight=1, missing=None, n_estimator=200,\n",
       "              n_estimators=100, n_jobs=1, nthread=None,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "              subsample=1)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # USING RANDOM FOREST CLASSIFIER\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rfc = RandomForestClassifier(bootstrap=True,n_estimators=200,criterion=\"gini\",random_state = 47,max_depth = 3,class_weight=siminv)\n",
    "# svmc = SVC(gamma = 0.01,C= 0.25,probability = True,shrinking =True,class_weight=tsftmax,break_ties=True, kernel=\"rbf\"  ,decision_function_shape = 'ovr',random_state = 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                       class_weight={0: 0.10526315789473684,\n",
      "                                     1: 0.07894736842105263,\n",
      "                                     2: 0.18045112781954886,\n",
      "                                     3: 0.06766917293233082,\n",
      "                                     4: 0.10150375939849623,\n",
      "                                     5: 0.17669172932330826,\n",
      "                                     6: 0.14285714285714285,\n",
      "                                     7: 0.14661654135338345},\n",
      "                       criterion='gini', max_depth=3, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=True, random_state=47, verbose=0,\n",
      "                       warm_start=False)\n",
      "SVC(C=0.25, break_ties=True, cache_size=200,\n",
      "    class_weight={0: 0.12245841926955647, 1: 0.11927786227100165,\n",
      "                  2: 0.1320208028812522, 3: 0.11794018071899233,\n",
      "                  4: 0.12199891354605118, 5: 0.13152541583553046,\n",
      "                  6: 0.1271497496322185, 7: 0.12762865584539734},\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1512,\n",
      "    kernel='rbf', max_iter=-1, probability=True, random_state=47,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=None, n_estimator=200,\n",
      "              n_estimators=100, n_jobs=1, nthread=None,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "              subsample=1)\n",
      "=====\n",
      "=====\n",
      "=====\n",
      "MAP [0.83, 0.85, 0.81]\n",
      "Class Name\t\t\t0\t\t1\t\t2\n",
      "Loss\t\t\t\t0.66\t\t0.75\t\t0.7\n",
      "Frustrative_Nonreward\t\t0.69\t\t0.67\t\t0.7\n",
      "Sleep_Wakefulness\t\t1.0\t\t1.0\t\t1.0\n",
      "Sustained_Threat\t\t0.59\t\t0.64\t\t0.57\n",
      "Potential_Threat_Anxiety\t0.95\t\t0.97\t\t0.96\n",
      "Circadian_Rhythms\t\t1.0\t\t1.0\t\t1.0\n",
      "Arousal\t\t\t\t0.94\t\t0.95\t\t0.96\n",
      "Acute_Threat_Fear\t\t0.79\t\t0.82\t\t0.62\n"
     ]
    }
   ],
   "source": [
    "# USING RANDOM FOREST CLASSIFIER\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(n_estimator=200)\n",
    "rfc = RandomForestClassifier(bootstrap=True,oob_score = True,n_estimators=200,criterion=\"gini\",random_state = 47,max_depth = 3,class_weight=siminv)\n",
    "svmc = SVC(gamma = 0.1512,C= 0.25,probability = True,shrinking =True,class_weight=tsftmax,break_ties=True, kernel=\"rbf\"  ,decision_function_shape = 'ovr',random_state = 47)\n",
    "map_list = []\n",
    "estimators = [rfc,svmc,xgb]\n",
    "for model in estimators:\n",
    "    print(model.fit(x_train, y_train))\n",
    "class_count = {}\n",
    "err = {}\n",
    "for i,model in enumerate(estimators):\n",
    "  aps = 0\n",
    "  err[i] = {}\n",
    "  for cl_ in construct_test.keys():\n",
    "    X_test = tfidf.transform(construct_test[cl_]['inp']).toarray()\n",
    "    y_pred = model.predict_proba(X_test)[:,cl_]\n",
    "    y_belongs = np.array(construct_test[cl_]['Belongs'].values).reshape(len(X_test),1)\n",
    "    t = ap(y_pred,y_belongs)\n",
    "    err[i][cl_] = round( t, 2)\n",
    "    aps += t\n",
    "  print(\"=====\")\n",
    "  map_list.append(round(aps/8,2))\n",
    "print(\"MAP\",list(map(lambda x:round(x,5),map_list)))\n",
    "st = \"Class Name\\t\\t\\t\"+ \"\\t\\t\".join([str(i) for i  in range(len(err.keys()))])\n",
    "print(st)\n",
    "for cl_ in construct_test.keys():\n",
    "    padd = \"\\t\\t\"\n",
    "    if len(revLabels[cl_]) < 15:\n",
    "        padd += \"\\t\\t\"\n",
    "    if len(revLabels[cl_]) > 22:\n",
    "        padd = \"\\t\"\n",
    "    st = revLabels[cl_]+padd+\"\\t\\t\".join([ str(round(err[j][cl_],4)) for j in range(len(err.keys()))])\n",
    "    print(st)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit39b187e956f148688106743f51c2bd62"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}