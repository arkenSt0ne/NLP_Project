{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit39b187e956f148688106743f51c2bd62",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('all')# download nltk files\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3e5a8258ca5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchi2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_stop(txt):\n",
    "  return [ c for c in txt if c not in stopwords.words(\"english\")]\n",
    "stemmer = PorterStemmer()\n",
    "def word_stemm(txt):\n",
    "  return [stemmer.stem(w) for w in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_files_train = glob.glob(\"./dataset/Task1/Train/*.xlsx\")\n",
    "xl_files_test = glob.glob(\"./dataset/Task1/Test/*.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['./dataset/Task1/Test/Loss.xlsx',\n './dataset/Task1/Test/Frustrative_Nonreward.xlsx',\n './dataset/Task1/Test/Sleep_Wakefulness.xlsx',\n './dataset/Task1/Test/Potential_Threat_Anxiety_.xlsx',\n './dataset/Task1/Test/Sustained_Threat.xlsx',\n './dataset/Task1/Test/Circadian_Rhythms.xlsx',\n './dataset/Task1/Test/Arousal.xlsx',\n './dataset/Task1/Test/Acute_Threat_Fear.xlsx']"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "xl_files_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "labels = {}\n",
    "revLabels = {}\n",
    "for i,xl in  enumerate(xl_files_train):\n",
    "    className = xl.split(\"/\")[-1][:-5]\n",
    "    labels[className] = i\n",
    "    revLabels[i] = className"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataframes\n",
    "frames = []\n",
    "for xl_file in xl_files_train:\n",
    "    df1 = pd.read_excel(xl_file)\n",
    "    className = xl_file.split(\"/\")[-1][:-5]\n",
    "    df1['Y'] = labels[className]\n",
    "    frames.append(df1)\n",
    "df_train = pd.concat(frames,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataframes\n",
    "frames = []\n",
    "for xl_file in xl_files_test:\n",
    "    df1 = pd.read_excel(xl_file)\n",
    "    className = xl_file.split(\"/\")[-1][:-5]\n",
    "    df1['Y'] = labels[className]\n",
    "    frames.append(df1)\n",
    "df_test = pd.concat(frames,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre process the text\n",
    "stop_words = stopwords.words(\"english\")\n",
    "cols = ['title','abstract']\n",
    "for col in cols :\n",
    "    df_train['c_'+col] = df_train[col].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]))\n",
    "    df_test['c_'+col] = df_test[col].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0      tinnitu relat distress appear strongli associ ...\n1      In studi examin effect trauma exposur substanc...\n2      research shown intoler uncertainti IU tendenc ...\n3      background fetal death caus women experi neg f...\n4      aim introduct To evalu effect calor restrict w...\n                             ...                        \n261    chronic elev hpa activ often associ fear anxie...\n262    the use fear condit extinct paradigm examin in...\n263    rational In studi use function magnet reson im...\n264    fear promot adapt respons threat howev level f...\n265    acut pain inform individu immin threat bodi da...\nName: abstract, Length: 266, dtype: object"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}